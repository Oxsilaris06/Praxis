<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Praxis | Chatbot Phi-3.5 Mini</title>
    <link rel="icon" href="https://oxsilaris06.github.io/Praxis/maskable_icon(2).png" type="image/png">
    <link href="https://fonts.googleapis.com/css2?family=Oswald:wght@400;500&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Saira+Stencil+One&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0" />
    <style>
        :root {
            --bg-body: #121212; --bg-container: #1e1e1e; --bg-interactive: #2a2a2a;
            --text-primary: #e0e0e0; --text-secondary: #95a5a6; --border-color: #444444;
            --accent-blue: #5b9bd5; --accent-hover: #4a7aa5; --danger-red: #c0392b;
            --success-green: #27ae60;
        }
        body.light-mode {
            --bg-body: #f0f2f5; --bg-container: #ffffff; --bg-interactive: #f8f9fa;
            --text-primary: #212529; --text-secondary: #6c757d; --accent-blue: #0033a0;
            --border-color: #dee2e6;
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        html { font-size: 16px; }
        body { font-family: 'Oswald', sans-serif; background-color: var(--bg-body); color: var(--text-primary); line-height: 1.6; padding: 10px; padding-bottom: 90px; }
        .container { width: 100%; max-width: 800px; margin: auto; background: var(--bg-container); padding: 20px; border-radius: 8px; border: 1px solid var(--border-color); }
        h1 { font-size: 2.2em; margin-bottom: 10px; color: var(--accent-blue); font-family: 'Saira Stencil One', sans-serif; text-align: center; }
        p.subtitle { text-align: center; color: var(--text-secondary); margin-bottom: 30px; }
        .section { padding: 0; margin-top: 10px; }

        /* Styles de chargement (conservés) */
        #model-loader { text-align: center; padding: 20px; background-color: var(--bg-interactive); border-radius: 8px; }
        #model-loader button { background-color: var(--accent-blue); color: white; padding: 14px 20px; border: none; border-radius: 5px; cursor: pointer; font-family: 'Oswald', sans-serif; font-size: 1.2em; margin-bottom: 15px; }
        #model-loader button:disabled { background-color: var(--text-secondary); cursor: not-allowed; }
        #model-status { color: var(--text-secondary); font-style: italic; min-height: 20px; transition: color 0.3s; }
        .progress-bar-container { width: 100%; background-color: var(--bg-body); border-radius: 5px; overflow: hidden; height: 25px; margin-top: 10px; display: none; }
        .progress-bar { width: 0%; height: 100%; background-color: var(--success-green); text-align: center; line-height: 25px; color: white; transition: width 0.3s ease; }

        /* Styles de chat (Nouveau/Modifié) */
        #chat-window { background-color: var(--bg-body); height: 60vh; max-height: 500px; overflow-y: auto; border-radius: 8px; padding: 20px; display: flex; flex-direction: column; gap: 20px; }
        
        .message-row { display: flex; width: 100%; }
        .user-row { justify-content: flex-end; }
        .ai-row { justify-content: flex-start; }

        .message-bubble { padding: 12px 16px; border-radius: 20px; max-width: 90%; line-height: 1.5; font-size: 1em; font-family: sans-serif; }
        
        /* Style Gemini-like */
        .user-message { background-color: var(--accent-blue); color: white; border-bottom-right-radius: 5px; }
        .ai-message { background-color: var(--bg-interactive); color: var(--text-primary); border: 1px solid var(--border-color); border-bottom-left-radius: 5px; }
        
        #input-area { position: sticky; bottom: 0; margin-top: 15px; display: flex; gap: 10px; background-color: var(--bg-container); padding: 10px; border-radius: 8px; border: 1px solid var(--border-color); }
        #user-input { flex-grow: 1; padding: 12px; border: none; border-radius: 5px; background-color: var(--bg-body); color: var(--text-primary); font-family: sans-serif; font-size: 1em; resize: none; overflow: auto; min-height: 48px; max-height: 150px; }
        
        #send-btn { background-color: var(--accent-blue); color: white; padding: 10px 15px; border: none; border-radius: 8px; cursor: pointer; font-family: 'Oswald', sans-serif; font-size: 1.1em; display: flex; align-items: center; justify-content: center; width: 50px; height: 50px; }
        #send-btn:disabled { background-color: var(--text-secondary); cursor: not-allowed; opacity: 0.6; }

        .spinner { border: 4px solid rgba(255,255,255,0.3); border-radius: 50%; border-top: 4px solid #fff; width: 20px; height: 20px; animation: spin 1s linear infinite; display: none;}
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="dark-mode">

    <div class="dock-menu" id="dockMenu">
        <a href="#" class="dock-menu-item" title="Accueil" onclick="location.reload()"><span class="material-symbols-outlined">home</span></a>
        <div class="dock-menu-item" id="darkModeToggle" title="Changer le thème"><span class="material-symbols-outlined" id="darkModeIcon">nightlight</span></div>
    </div>

    <div class="container">
        <h1>Praxis</h1>
        <p class="subtitle">Chatbot d'IA Locale (Phi-3.5 Mini)</p>

        <div class="section" id="model-loader-section">
            <h2>1. Initialisation de l'IA</h2>
            <div id="model-loader">
                <p style="color: var(--text-secondary); margin-bottom: 20px; text-align: center;">Le modèle d'IA doit être chargé avant de commencer le chat.</p>
                <button id="load-model-btn">Charger le Modèle de Chat (Phi-3.5 Mini)</button>
                <div id="model-status">Statut : Inactif</div>
                <div class="progress-bar-container" id="progress-container"><div class="progress-bar" id="progress-bar">0%</div></div>
            </div>
        </div>

        <div class="section" id="chat-interface" style="display:none;">
            <div id="chat-window">
                <div class="ai-row message-row">
                    <div class="ai-message message-bubble">Bonjour ! Je suis Phi-3.5 Mini, un modèle d'IA qui tourne directement dans votre navigateur. Comment puis-je vous aider aujourd'hui ?</div>
                </div>
            </div>
            
            <div id="input-area">
                <textarea id="user-input" placeholder="Tapez votre message ici..." rows="1"></textarea>
                <button id="send-btn" disabled>
                    <span class="material-symbols-outlined" id="send-icon">send</span>
                    <div class="spinner" id="send-spinner"></div>
                </button>
            </div>
        </div>
        
        <div class="console-container" id="model-console-container" style="display:none;">
            <h4>Journal d'Installation</h4>
            <div class="console-output" id="model-console-output"></div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/marked@4.0.10/marked.min.js"></script>
    
    <script type="module">
        import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@latest'; 

        const MODEL_NAME = 'onnx-community/Phi-3.5-mini-instruct-onnx-web';
        const TASK = 'text-generation';
        
        const dom = {
            loadModelBtn: document.getElementById('load-model-btn'), modelStatus: document.getElementById('model-status'),
            progressContainer: document.getElementById('progress-container'), progressBar: document.getElementById('progress-bar'),
            modelConsoleContainer: document.getElementById('model-console-container'), modelConsoleOutput: document.getElementById('model-console-output'),
            modelLoaderSection: document.getElementById('model-loader-section'),
            chatInterface: document.getElementById('chat-interface'),
            chatWindow: document.getElementById('chat-window'),
            userInput: document.getElementById('user-input'),
            sendBtn: document.getElementById('send-btn'), sendIcon: document.getElementById('send-icon'),
            sendSpinner: document.getElementById('send-spinner'),
            darkModeToggle: document.getElementById('darkModeToggle'),
        };

        let state = { pipe: null, isProcessing: false, history: [] };
        
        // Fonction utilitaire pour le journal d'installation (masqué)
        function logTo(consoleElement, message, type = 'info') {
            const logLine = document.createElement('p');
            logLine.className = 'log-line';
            const time = new Date().toLocaleTimeString();
            logLine.textContent = `[${time}] ${message}`;
            if (type === 'error') logLine.classList.add('log-error');
            else if (type === 'success') logLine.classList.add('log-success');
            consoleElement.appendChild(logLine);
            consoleElement.scrollTop = consoleElement.scrollHeight;
        }
        
        function switchToChatView() {
            dom.modelLoaderSection.style.display = 'none';
            dom.chatInterface.style.display = 'block';
            dom.sendBtn.disabled = false;
        }

        // Crée la bulle de message dans la fenêtre de chat
        function createMessageBubble(text, sender) {
            const row = document.createElement('div');
            row.className = `message-row ${sender}-row`;

            const bubble = document.createElement('div');
            bubble.className = `message-bubble ${sender}-message`;
            
            // Si c'est l'IA qui parle, le texte est formaté en Markdown
            bubble.innerHTML = sender === 'ai' ? marked.parse(text) : text; 
            
            row.appendChild(bubble);
            dom.chatWindow.appendChild(row);
            dom.chatWindow.scrollTop = dom.chatWindow.scrollHeight;

            // Ajout à l'historique
            state.history.push({ role: sender === 'user' ? 'user' : 'assistant', content: text });
        }

        async function loadModel() {
            if (state.pipe) {
                switchToChatView();
                return;
            }

            dom.loadModelBtn.disabled = true;
            dom.progressContainer.style.display = 'block';
            dom.modelConsoleContainer.style.display = 'block';
            
            try {
                logTo(dom.modelConsoleOutput, `▶️ Démarrage du téléchargement du modèle ${MODEL_NAME}...`);
                
                // 🌟 CORRECTION DES BUGS CRITIQUES APPLIQUÉE :
                state.pipe = await pipeline(TASK, MODEL_NAME, {
                    // 1. Corrige l'erreur 404 en spécifiant le bon fichier ONNX quantifié (q4f16.onnx)
                    model_file: 'onnx/model_q4f16.onnx', 
                    // 2. Optimisations de performance pour le mobile et la mémoire
                    dtype: 'fp16', 
                    executionModel: 'on-demand',
                    progress_callback: (p) => {
                        if (p.status === 'ready') {
                            dom.modelStatus.textContent = 'Le modèle est prêt ! Initialisation...';
                            return;
                        }
                        if (typeof p.progress === 'number') {
                            const percentage = p.progress.toFixed(2);
                            dom.progressBar.style.width = percentage + '%';
                            dom.progressBar.textContent = `${percentage}%`;
                        }
                        let statusText = `[${p.status}] ${p.file || ''}`;
                        dom.modelStatus.textContent = `Statut : ${statusText}`;
                        const progressLog = typeof p.progress === 'number' ? `(${p.progress.toFixed(1)}%)` : '';
                        logTo(dom.modelConsoleOutput, `${statusText} ${progressLog}`);
                    }
                });
                
                logTo(dom.modelConsoleOutput, '✅ Modèle initialisé avec succès.', 'success');
                switchToChatView();

            } catch (error) {
                logTo(dom.modelConsoleOutput, '❌ ERREUR CRITIQUE LORS DU CHARGEMENT', 'error');
                logTo(dom.modelConsoleOutput, `Message : ${error.message}`, 'error');
                dom.modelStatus.textContent = "Erreur de chargement. Consulter le journal.";
                dom.modelStatus.style.color = 'var(--danger-red)';
                dom.loadModelBtn.disabled = false;
            }
        }
        
        // Reconstruit l'historique de chat pour le prompt, en utilisant le format du modèle Phi
        function buildPrompt(newMessage) {
            let fullPrompt = "";
            
            // Ajouter le contexte (historique)
            state.history.forEach(msg => {
                if (msg.role === 'user') {
                    fullPrompt += `<|user|>\n${msg.content}\n<|end|>\n`;
                } else if (msg.role === 'assistant') {
                    fullPrompt += `<|assistant|>\n${msg.content}\n<|end|>\n`;
                }
            });

            // Ajouter le nouveau message et la balise d'ouverture de l'assistant
            fullPrompt += `<|user|>\n${newMessage}\n<|end|>\n<|assistant|>`;
            
            return fullPrompt;
        }

        async function sendMessage() {
            if (!state.pipe || state.isProcessing) return;

            const userText = dom.userInput.value.trim();
            if (!userText) return;

            state.isProcessing = true;
            dom.sendBtn.disabled = true;
            dom.sendIcon.style.display = 'none';
            dom.sendSpinner.style.display = 'block';
            
            // 1. Afficher le message utilisateur et l'ajouter à l'historique
            createMessageBubble(userText, 'user');
            dom.userInput.value = '';

            try {
                // 2. Construire le prompt complet avec l'historique
                const prompt = buildPrompt(userText);
                
                const generationConfig = { 
                    max_new_tokens: 512, 
                    temperature: 0.7,
                    repetition_penalty: 1.1 
                };

                const output = await state.pipe(prompt, generationConfig);
                let response = output[0].generated_text;

                // 3. Nettoyer la réponse: Le modèle peut répéter une partie du prompt
                const assistantIndex = response.lastIndexOf('<|assistant|>');
                if (assistantIndex !== -1) {
                    response = response.substring(assistantIndex + '<|assistant|>'.length).trim();
                } else {
                     // Si le modèle n'a pas inclus la balise, on coupe juste le prompt
                    const userIndex = response.lastIndexOf('<|user|>');
                    if (userIndex !== -1) {
                        response = response.substring(response.lastIndexOf(userText) + userText.length).trim();
                    }
                }
                
                // 4. Afficher la réponse de l'IA et l'ajouter à l'historique
                createMessageBubble(response, 'ai');

            } catch (error) {
                // Si le crash mémoire se produit ici (Erreur brute 478...), il faut le logguer.
                createMessageBubble("❌ Erreur d'inférence. Le modèle a crashé. Votre prompt était peut-être trop long ou la mémoire est insuffisante.", 'ai');
                logTo(dom.modelConsoleOutput, `Erreur d'inférence: ${error.message || JSON.stringify(error)}`, 'error');
            } finally {
                state.isProcessing = false;
                dom.sendBtn.disabled = false;
                dom.sendIcon.style.display = 'block';
                dom.sendSpinner.style.display = 'none';
                dom.userInput.focus();
                // Assurer que le champ de texte s'ajuste après l'envoi
                adjustTextareaHeight();
            }
        }
        
        // Fonction pour ajuster la hauteur du textarea (pour une interface fluide)
        function adjustTextareaHeight() {
            const textarea = dom.userInput;
            textarea.style.height = 'auto'; 
            textarea.style.height = (textarea.scrollHeight) + 'px';
        }

        // Événements
        dom.loadModelBtn.addEventListener('click', loadModel);
        dom.sendBtn.addEventListener('click', sendMessage);
        dom.userInput.addEventListener('input', adjustTextareaHeight);
        dom.userInput.addEventListener('keypress', (e) => {
            // Envoyer avec Entrée, mais ne pas envoyer si Maj+Entrée (saut de ligne)
            if (e.key === 'Enter' && !e.shiftKey && !dom.sendBtn.disabled) {
                e.preventDefault(); 
                sendMessage();
            }
        });
        
        // Gestion du Dark Mode (conservée)
        dom.darkModeToggle.addEventListener('click', () => {
            document.body.classList.toggle('light-mode'); document.body.classList.toggle('dark-mode');
            const isDarkMode = document.body.classList.contains('dark-mode');
            localStorage.setItem('theme', isDarkMode ? 'dark' : 'light');
            document.getElementById('darkModeIcon').textContent = isDarkMode ? 'nightlight' : 'clear_day';
        });

        document.addEventListener('DOMContentLoaded', () => {
            if (localStorage.getItem('theme') === 'light') {
                document.body.classList.replace('dark-mode', 'light-mode');
                document.getElementById('darkModeIcon').textContent = 'clear_day';
            }
        });
    </script>
</body>
</html>
